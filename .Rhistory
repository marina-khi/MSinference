#      xlab="", ylab = "", type = "l", col = "#604c38")
# lines((1:100) / 100, lambda_vec, type = "l", col = "#EB811B")
# title(main = expression(Plot ~ of ~ the ~ "functions" ~ lambda[1] ~ and ~ lambda), line = 1)
# title(xlab="u", line=1.5)
# legend("topright", inset = 0.02, legend=c(expression(lambda[1](u) ~" "), expression(lambda(u) ~" ")),
#        col = c("#604c38", "#EB811B"), lty = 1, cex = 0.95, ncol = 1)
# dev.off()
#
# lambda_vec_1 <- lambda_fct((1:100) / 100, c = 1000, height = 5000, position = 9)
# lambda_vec   <- lambda_fct((1:100) / 100, c = 1000, height = 5000, position = 10)
#
# pdf(paste0("plots/lambda_fcts_shift.pdf"), width=4.5, height=3, paper="special")
# par(mar = c(3, 2, 2, 0)) #Margins for each plot
# par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
# par(mgp = c(3, 0.5, 0))
# plot((1:100) / 100, lambda_vec_1,  ylim = c(0, max(lambda_vec_1, lambda_vec) + 100),
#      xlab="", ylab = "", type = "l", col = "#604c38")
# lines((1:100) / 100, lambda_vec, type = "l", col = "#EB811B")
# title(main = expression(Plot ~ of ~ the ~ "functions" ~ lambda[1] ~ and ~ lambda), line = 1)
# title(xlab="u", line=1.5)
# legend("topright", inset = 0.02, legend=c(expression(lambda[1](u) ~" "), expression(lambda(u) ~" ")),
#        col = c("#604c38", "#EB811B"), lty = 1, cex = 0.95, ncol = 1)
# dev.off()
pdf("plots/Germany_and_Italy.pdf", width=5.5, height=3, paper="special")
par(cex = 1, tck = -0.025)
par(mar = c(3, 3, 0.5, 0)) #Margins for each plot
par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
plot(covid_mat[, 1], ylim=c(min(covid_mat[, 1], covid_mat[, 5]), max(covid_mat[, 1], covid_mat[, 5])), type="l",
col="#EB811B", ylab="", xlab="", mgp=c(1, 0.5, 0))
lines(covid_mat[, 5], col="#604c38")
title(ylab = "New daily cases", line = 1.7, cex.lab = 0.9)
title(xlab = "days since first Monday after reaching 100 cases", line = 1.7, cex.lab = 0.9)
legend("topright", inset = 0.02, legend=c("Germany", "Italy"),
col = c("#EB811B", "#604c38"), lty = 1, cex = 0.95, ncol = 1)
dev.off()
pdf("plots/Germany_and_Italy_1.pdf", width=5.5, height=3, paper="special")
par(cex = 1, tck = -0.025)
par(mar = c(3, 3, 0.5, 0)) #Margins for each plot
par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
plot(covid_mat[, 1], ylim=c(min(covid_mat[, 1], covid_mat[, 5]), max(covid_mat[, 1], covid_mat[, 5])), type="l",
col="#EB811B", ylab="", xlab="", mgp=c(1, 0.5, 0))
rect(xleft=17, xright = 27, ybottom=par("usr")[3], ytop=par("usr")[4],
density=40, col = "#d3d3d3", border = NA)
lines(covid_mat[, 5], col="#604c38")
lines(covid_mat[, 1], col="#EB811B")
segments(17, par("usr")[3], 27, par("usr")[3], col="#604c38", lwd = 3)
title(ylab = "New daily cases", line = 1.7, cex.lab = 0.9)
title(xlab = "days since first Monday after reaching 100 cases", line = 1.7, cex.lab = 0.9)
legend("topright", inset = 0.02, legend=c("Germany", "Italy"),
col = c("#EB811B", "#604c38"), lty = 1, cex = 0.95, ncol = 1)
dev.off()
pdf("plots/Germany_and_Italy_2.pdf", width=5.5, height=3, paper="special")
par(cex = 1, tck = -0.025)
par(mar = c(3, 3, 0.5, 0)) #Margins for each plot
par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
plot(covid_mat[, 1], ylim=c(min(covid_mat[, 1], covid_mat[, 5]), max(covid_mat[, 1], covid_mat[, 5])), type="l",
col="#EB811B", ylab="", xlab="", mgp=c(1, 0.5, 0))
rect(xleft=17, xright = 27, ybottom=par("usr")[3], ytop=par("usr")[4],
density=40, col = "#d3d3d3", border = NA)
rect(xleft=41, xright = 86, ybottom=par("usr")[3], ytop=par("usr")[4],
density=40, col = "#d3d3d3", border = NA)
lines(covid_mat[, 5], col="#604c38")
lines(covid_mat[, 1], col="#EB811B")
segments(17, par("usr")[3], 27, par("usr")[3], col="#604c38", lwd = 3)
segments(41, par("usr")[3], 86, par("usr")[3], col="#604c38", lwd = 3)
title(ylab = "New daily cases", line = 1.7, cex.lab = 0.9)
title(xlab = "days since first Monday after reaching 100 cases", line = 1.7, cex.lab = 0.9)
legend("topright", inset = 0.02, legend=c("Germany", "Italy"),
col = c("#EB811B", "#604c38"), lty = 1, cex = 0.95, ncol = 1)
dev.off()
# #Plots of lambda functions
# n_sim     <- 5000               # number of simulation runs for power and size
# sim_runs  <- 5000               # number of simulation runs to produce critical values
# alpha_vec <- c(0.01, 0.05, 0.1) # different significance levels
# n_ts_vec  <- c(5, 10, 50)       # different number of time series
# t_len_vec <- c(100, 250, 500)   # different time series lengths
# sigma_vec <- c(15, 10, 20)      # different overdispersion parameter
#
# number_of_cols <- length(n_ts_vec) * length(alpha_vec) #Needed for the output
#
# #As the mean function in the size simulations, we take the following function:
# #lambda(u) = 5000 * exp(-(10 * u - 3) ^ 2 / 2) + 1000 for 0 <= u <= 1.
# #Here is the plot of this function:
#
# lambda_vec <- lambda_fct((1:100) / 100)
#
# pdf(paste0("plots_new/lambda_fct.pdf"), width=5, height=3, paper="special")
# par(mar = c(3, 2, 2, 0)) #Margins for each plot
# par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
# plot((1:100) / 100, lambda_vec,  ylim = c(0, max(lambda_vec) + 100), xlab="u",
#      ylab = "", mgp=c(2,0.5,0), type = "l")
# title(main = expression(Plot ~ of ~ the ~ "function" ~ lambda), line = 1)
# dev.off()
#
#
# lambda_vec_1 <- lambda_fct((1:100) / 100, c = 1000, height = 6000, position = 10)
# lambda_vec   <- lambda_fct((1:100) / 100, c = 1000, height = 5000, position = 10)
#
# pdf(paste0("plots/lambda_fcts_height.pdf"), width=4.5, height=3, paper="special")
# par(mar = c(3, 2, 2, 0)) #Margins for each plot
# par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
# par(mgp = c(3, 0.5, 0))
# plot((1:100) / 100, lambda_vec_1,  ylim = c(0, max(lambda_vec_1, lambda_vec) + 100),
#      xlab="", ylab = "", type = "l", col = "#604c38")
# lines((1:100) / 100, lambda_vec, type = "l", col = "#EB811B")
# title(main = expression(Plot ~ of ~ the ~ "functions" ~ lambda[1] ~ and ~ lambda), line = 1)
# title(xlab="u", line=1.5)
# legend("topright", inset = 0.02, legend=c(expression(lambda[1](u) ~" "), expression(lambda(u) ~" ")),
#        col = c("#604c38", "#EB811B"), lty = 1, cex = 0.95, ncol = 1)
# dev.off()
#
# lambda_vec_1 <- lambda_fct((1:100) / 100, c = 1000, height = 5000, position = 9)
# lambda_vec   <- lambda_fct((1:100) / 100, c = 1000, height = 5000, position = 10)
#
# pdf(paste0("plots/lambda_fcts_shift.pdf"), width=4.5, height=3, paper="special")
# par(mar = c(3, 2, 2, 0)) #Margins for each plot
# par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
# par(mgp = c(3, 0.5, 0))
# plot((1:100) / 100, lambda_vec_1,  ylim = c(0, max(lambda_vec_1, lambda_vec) + 100),
#      xlab="", ylab = "", type = "l", col = "#604c38")
# lines((1:100) / 100, lambda_vec, type = "l", col = "#EB811B")
# title(main = expression(Plot ~ of ~ the ~ "functions" ~ lambda[1] ~ and ~ lambda), line = 1)
# title(xlab="u", line=1.5)
# legend("topright", inset = 0.02, legend=c(expression(lambda[1](u) ~" "), expression(lambda(u) ~" ")),
#        col = c("#604c38", "#EB811B"), lty = 1, cex = 0.95, ncol = 1)
# dev.off()
pdf("plots/Germany_and_Italy.pdf", width=5.5, height=3, paper="special")
par(cex = 1, tck = -0.025)
par(mar = c(3, 3, 0.5, 0)) #Margins for each plot
par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
plot(covid_mat[, 1], ylim=c(min(covid_mat[, 1], covid_mat[, 5]), max(covid_mat[, 1], covid_mat[, 5])), type="l",
col="#EB811B", ylab="", xlab="", mgp=c(1, 0.5, 0))
lines(covid_mat[, 5], col="#604c38")
title(ylab = "New daily cases", line = 1.7, cex.lab = 0.9)
title(xlab = "days since first Monday after reaching 100 cases", line = 1.7, cex.lab = 0.9)
legend("topright", inset = 0.02, legend=c("Germany", "Italy"),
col = c("#EB811B", "#604c38"), lty = 1, cex = 0.95, ncol = 1)
dev.off()
pdf("plots/Germany_and_Italy_1.pdf", width=5.5, height=3, paper="special")
par(cex = 1, tck = -0.025)
par(mar = c(3, 3, 0.5, 0)) #Margins for each plot
par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
plot(covid_mat[, 1], ylim=c(min(covid_mat[, 1], covid_mat[, 5]), max(covid_mat[, 1], covid_mat[, 5])), type="l",
col="#EB811B", ylab="", xlab="", mgp=c(1, 0.5, 0))
rect(xleft=18, xright = 27, ybottom=par("usr")[3], ytop=par("usr")[4],
density=40, col = "#d3d3d3", border = NA)
lines(covid_mat[, 5], col="#604c38")
lines(covid_mat[, 1], col="#EB811B")
segments(18, par("usr")[3], 27, par("usr")[3], col="#604c38", lwd = 3)
title(ylab = "New daily cases", line = 1.7, cex.lab = 0.9)
title(xlab = "days since first Monday after reaching 100 cases", line = 1.7, cex.lab = 0.9)
legend("topright", inset = 0.02, legend=c("Germany", "Italy"),
col = c("#EB811B", "#604c38"), lty = 1, cex = 0.95, ncol = 1)
dev.off()
pdf("plots/Germany_and_Italy_2.pdf", width=5.5, height=3, paper="special")
par(cex = 1, tck = -0.025)
par(mar = c(3, 3, 0.5, 0)) #Margins for each plot
par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
plot(covid_mat[, 1], ylim=c(min(covid_mat[, 1], covid_mat[, 5]), max(covid_mat[, 1], covid_mat[, 5])), type="l",
col="#EB811B", ylab="", xlab="", mgp=c(1, 0.5, 0))
rect(xleft=18, xright = 27, ybottom=par("usr")[3], ytop=par("usr")[4],
density=40, col = "#d3d3d3", border = NA)
rect(xleft=41, xright = 88, ybottom=par("usr")[3], ytop=par("usr")[4],
density=40, col = "#d3d3d3", border = NA)
lines(covid_mat[, 5], col="#604c38")
lines(covid_mat[, 1], col="#EB811B")
segments(18, par("usr")[3], 27, par("usr")[3], col="#604c38", lwd = 3)
segments(41, par("usr")[3], 88, par("usr")[3], col="#604c38", lwd = 3)
title(ylab = "New daily cases", line = 1.7, cex.lab = 0.9)
title(xlab = "days since first Monday after reaching 100 cases", line = 1.7, cex.lab = 0.9)
legend("topright", inset = 0.02, legend=c("Germany", "Italy"),
col = c("#EB811B", "#604c38"), lty = 1, cex = 0.95, ncol = 1)
dev.off()
# #Plots of lambda functions
# n_sim     <- 5000               # number of simulation runs for power and size
# sim_runs  <- 5000               # number of simulation runs to produce critical values
# alpha_vec <- c(0.01, 0.05, 0.1) # different significance levels
# n_ts_vec  <- c(5, 10, 50)       # different number of time series
# t_len_vec <- c(100, 250, 500)   # different time series lengths
# sigma_vec <- c(15, 10, 20)      # different overdispersion parameter
#
# number_of_cols <- length(n_ts_vec) * length(alpha_vec) #Needed for the output
#
# #As the mean function in the size simulations, we take the following function:
# #lambda(u) = 5000 * exp(-(10 * u - 3) ^ 2 / 2) + 1000 for 0 <= u <= 1.
# #Here is the plot of this function:
#
# lambda_vec <- lambda_fct((1:100) / 100)
#
# pdf(paste0("plots_new/lambda_fct.pdf"), width=5, height=3, paper="special")
# par(mar = c(3, 2, 2, 0)) #Margins for each plot
# par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
# plot((1:100) / 100, lambda_vec,  ylim = c(0, max(lambda_vec) + 100), xlab="u",
#      ylab = "", mgp=c(2,0.5,0), type = "l")
# title(main = expression(Plot ~ of ~ the ~ "function" ~ lambda), line = 1)
# dev.off()
#
#
# lambda_vec_1 <- lambda_fct((1:100) / 100, c = 1000, height = 6000, position = 10)
# lambda_vec   <- lambda_fct((1:100) / 100, c = 1000, height = 5000, position = 10)
#
# pdf(paste0("plots/lambda_fcts_height.pdf"), width=4.5, height=3, paper="special")
# par(mar = c(3, 2, 2, 0)) #Margins for each plot
# par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
# par(mgp = c(3, 0.5, 0))
# plot((1:100) / 100, lambda_vec_1,  ylim = c(0, max(lambda_vec_1, lambda_vec) + 100),
#      xlab="", ylab = "", type = "l", col = "#604c38")
# lines((1:100) / 100, lambda_vec, type = "l", col = "#EB811B")
# title(main = expression(Plot ~ of ~ the ~ "functions" ~ lambda[1] ~ and ~ lambda), line = 1)
# title(xlab="u", line=1.5)
# legend("topright", inset = 0.02, legend=c(expression(lambda[1](u) ~" "), expression(lambda(u) ~" ")),
#        col = c("#604c38", "#EB811B"), lty = 1, cex = 0.95, ncol = 1)
# dev.off()
#
# lambda_vec_1 <- lambda_fct((1:100) / 100, c = 1000, height = 5000, position = 9)
# lambda_vec   <- lambda_fct((1:100) / 100, c = 1000, height = 5000, position = 10)
#
# pdf(paste0("plots/lambda_fcts_shift.pdf"), width=4.5, height=3, paper="special")
# par(mar = c(3, 2, 2, 0)) #Margins for each plot
# par(oma = c(0.2, 0.2, 0.2, 0.2)) #Outer margins
# par(mgp = c(3, 0.5, 0))
# plot((1:100) / 100, lambda_vec_1,  ylim = c(0, max(lambda_vec_1, lambda_vec) + 100),
#      xlab="", ylab = "", type = "l", col = "#604c38")
# lines((1:100) / 100, lambda_vec, type = "l", col = "#EB811B")
# title(main = expression(Plot ~ of ~ the ~ "functions" ~ lambda[1] ~ and ~ lambda), line = 1)
# title(xlab="u", line=1.5)
# legend("topright", inset = 0.02, legend=c(expression(lambda[1](u) ~" "), expression(lambda(u) ~" ")),
#        col = c("#604c38", "#EB811B"), lty = 1, cex = 0.95, ncol = 1)
# dev.off()
install.packages(c("gridExtra", "np"))
install.packages("knitr")
install.packages("ggplot2")
install.packages("np")
install.packages("KernSmooth")
install.packages("gridExtra")
install.packages("gtable")
install.packages("scales")
library("knitr")   # Combining LaTeX and R-Code
knit_theme$set("edit-kwrite")
#set global chunk options
opts_chunk$set(fig.path='graphs/', fig.align='center', fig.show='hold')
options(formatR.arrow=TRUE, width=90)
# Libraries
library("ggplot2", quietly=TRUE)     #Plotting
library("np", quietly=TRUE)          #Nonparametric Statistics
library("KernSmooth", quietly=TRUE)
library("gridExtra", quietly=TRUE)   #Arraging multipl plots
library("gtable", quietly=TRUE)
library("scales", quietly=TRUE)      #Transparent colors
setwd("~/Desktop/Work/proseminar/Week 2")
library("knitr")   # Combining LaTeX and R-Code
knit_theme$set("edit-kwrite")
knit_theme$get("edit-kwrite")
?knit_theme
knit_theme$get()
opts_knit$set(out.format = "latex")
knit_theme$set("edit-vim")
knit_theme$set("edit-kwrite")
knit("Untitled.Rnw")
# Chunk 1
knitr::opts_chunk$set(fig.width=12, fig.height=8)
# Chunk 2
require(multiscale)
data(temperature, package = "multiscale")
str(temperature)
# Chunk 3
t_len    <- length(temperature)
t_len
ts_start <- 1659
# Chunk 4
grid <- construct_grid(t_len)
str(grid$gset, max.level = 1, vec.len = 4)
# Chunk 5
parameters <- estimate_lrv(data = temperature,
q = 25, r_bar = 10, p = 2)
cat("Long-run variance is equal to ", parameters$lrv, "\n")
sigmahat <- sqrt(parameters$lrv)
# Chunk 6
alpha    <- 0.05
sim_runs <- 5000
# Chunk 7
deriv_order = 1
# Chunk 8
quantiles <- compute_quantiles(t_len = t_len, grid = grid,
sim_runs = 10)
probs <- as.vector(quantiles$quant[1, ])
pos   <- which.min(abs(probs - (1 - alpha)))
quant <- quantiles$quant[2, pos]
quant
# Chunk 9
result <- compute_statistics(data = temperature,
sigma = sigmahat,
grid = grid,
deriv_order = deriv_order)
str(result, max.level = 2, vec.len = 2)
# Chunk 10
gset         <- result$gset_with_vals
test_results <- (gset$vals_cor > quant) * sign(gset$vals)
gset$test    <- test_results
str(gset, max.level = 1, vec.len = 2)
# Chunk 11
sum(gset$test == -1)
# Chunk 12
results <- multiscale_test(data = temperature,
sigma = sigmahat,
grid = grid,
alpha = alpha,
deriv_order = deriv_order,
sim_runs = 10)
str(results, max.level = 2, vec.len = 2)
# Chunk 13
plot(ts_start:(ts_start + t_len - 1), temperature, type = 'l',
lty = 1, xlab = 'year', ylab = 'temperature',
ylim = c(min(temperature) - 0.1, max(temperature) + 0.1))
title(main = "(a) observed yearly temperature", font.main = 1,
line = 0.5)
# Chunk 14
# Epanechnikov kernel function, which is defined
# as f(x) = 3/4(1-x^2) for |x|<1 and 0 elsewhere
epanechnikov <- function(x)
{
if (abs(x)<1)
{
result = 3/4 * (1 - x*x)
} else {
result = 0
}
return(result)
}
smoothing <- function(u, data_p, grid_p, bw){
res = 0
norm = 0
for (i in 1:length(data_p)){
res = res + epanechnikov((u - grid_p[i]) / bw) * data_p[i]
norm = norm + epanechnikov((u - grid_p[i]) / bw)
}
return(res/norm)
}
bws <- c(0.01, 0.05, 0.1, 0.15, 0.2)
grid_points <- seq(from = 1 / t_len, to = 1,
length.out = t_len)
plot(NA, xlim = c(1659, 2019), ylim = c(8, 10.5),
xlab = 'year', ylab = 'temperature',
yaxp  = c(8, 10, 2), xaxp = c(1675, 2025, 7),
mgp = c(2,0.5,0))
for (i in 1:5){
smoothed <- mapply(smoothing, grid_points,
MoreArgs = list(temperature,
grid_points,
bws[i]))
lines(ts_start:(ts_start + t_len - 1), smoothed,
lty = i)
}
legend(1900, 8.5, legend=c("bw = 0.01", "bw = 0.05", "bw = 0.10",
"bw = 0.15", "bw = 0.2"),
lty = 1:5, cex = 0.95, ncol=1)
title(main = "(b) smoothed time series for different bandwidths",
font.main = 1, line = 0.5)
gset   <- results$gset_with_vals
reject <- subset(gset, (test == 1 & u - h >= 0 & u + h <= 1),
select = c(u, h))
p_plus <- data.frame('startpoint' = (reject$u - reject$h) *
t_len + ts_start,
'endpoint' = (reject$u + reject$h) * t_len +
ts_start, 'values' = 0)
p_plus$values <- (1:nrow(p_plus)) / nrow(p_plus)
p_plus_min    <- compute_minimal_intervals(p_plus)
plot(NA, xlim=c(ts_start, ts_start + t_len - 1),
ylim = c(0, 1 + 1 / nrow(p_plus)),
xlab=" ", mgp=c(2, 0.5, 0), yaxt = "n", ylab = "")
title(main = "(c) (minimal) intervals produced by the test",
font.main = 1, line = 0.5)
title(xlab = "year", line = 1.7, cex.lab = 0.9)
segments(p_plus_min$startpoint, p_plus_min$values,
p_plus_min$endpoint, p_plus_min$values, lwd = 2)
segments(p_plus$startpoint, p_plus$values,
p_plus$endpoint, p_plus$values,
col = "gray")
require(multiscale)
data(covid, package = "multiscale")
str(covid)
covid <- covid[, c("DEU", "GBR", "ESP", "FRA", "ITA")]
covid <- na.omit(covid)
# Chunk 17
covid <- covid[, c("DEU", "GBR", "ESP", "FRA", "ITA")]
covid <- na.omit(covid)
# Chunk 18
n     <- ncol(covid)
t_len <- nrow(covid)
n
t_len
# Chunk 19
sum(covid < 0)
covid[covid < 0] <- 0
# Chunk 20
matplot(1:t_len, covid, type = 'l', lty = 1, col = 1:t_len,
xlab = 'Number of days since 100th case', ylab = 'cases')
legend("topright", legend = c("DEU", "GBR", "ESP", "FRA", "ITA"),
inset = 0.02, lty = 1, col = 1:t_len, cex = 0.8)
# Chunk 21
sigma_vec <- rep(0, n)
for (i in 1:n){
diffs <- (covid[2:t_len, i] - covid[1:(t_len - 1), i])
sigma_squared <- sum(diffs^2) / (2 * sum(covid[, i]))
sigma_vec[i] <- sqrt(sigma_squared)
}
sigmahat <- sqrt(mean(sigma_vec * sigma_vec))
sigmahat
# Chunk 22
alpha    <- 0.05
sim_runs <- 5000
# Chunk 23
ijset           <- expand.grid(i = 1:n, j = 1:n)
ijset           <- ijset[ijset$i < ijset$j, ]
rownames(ijset) <- NULL
ijset
grid <- construct_weekly_grid(t_len, min_len = 7, nmbr_of_wks = 4)
# Chunk 24
intervals <- data.frame('left' = grid$gset$u - grid$gset$h,
'right' = grid$gset$u + grid$gset$h,
'v' = 0)
intervals$v <- (1:nrow(intervals)) / nrow(intervals)
plot(NA, xlim=c(0,t_len),  ylim = c(0, 1 + 1/nrow(intervals)),
xlab="days", ylab = "", yaxt= "n", mgp=c(2,0.5,0))
title(main = expression(The ~ family ~ of ~ intervals ~ italic(F)),
line = 1)
segments(intervals$left * t_len, intervals$v,
intervals$right * t_len, intervals$v,
lwd = 2)
# Chunk 25
quantiles <- compute_quantiles(t_len = t_len, grid = grid,
n_ts = n, ijset = ijset,
sigma = sigmahat,
sim_runs = sim_runs)
probs <- as.vector(quantiles$quant[1, ])
pos   <- which.min(abs(probs - (1 - alpha)))
quant <- quantiles$quant[2, pos]
quant
# Chunk 26
result <- compute_statistics(data = covid, sigma = sigmahat,
n_ts = n, grid = grid)
str(result, max.level = 3, vec.len = 2, list.len = 2)
# Chunk 27
gset_with_values <- result$gset_with_values
for (i in seq_len(nrow(ijset))) {
test_results <- gset_with_values[[i]]$vals > quant
gset_with_values[[i]]$test <- test_results
}
str(gset_with_values, max.level = 2, vec.len = 2, list.len = 2)
# Chunk 28
results <- multiscale_test(data = covid, sigma = sigmahat,
n_ts = n, grid = grid, ijset = ijset,
alpha = alpha,
sim_runs = sim_runs)
str(results, max.level = 3, vec.len = 2, list.len = 2)
# Chunk 29
plot(covid[, 1], ylim=c(min(covid[, 1], covid[, 2]),
max(covid[, 1], covid[, 2])),
type="l", col="blue", ylab="", xlab="", mgp=c(1, 0.5, 0))
lines(covid[, 2], col="red")
title(main = "(a) observed new cases per day", font.main = 1,
line = 0.5)
legend("topright", inset = 0.02, legend=c("Germany", "UK"),
col = c("blue", "red"), lty = 1, cex = 0.95, ncol = 1)
# Chunk 30
smoothing <- function(u, data_p, grid_p, bw){
result      = 0
norm        = 0
T_size      = length(data_p)
result = sum((abs((grid_p - u) / bw) <= 1) * data_p)
norm = sum((abs((grid_p - u) / bw) <= 1))
return(result/norm)
}
grid_points <- seq(from = 1 / t_len, to = 1, length.out = t_len)
smoothed_1  <- mapply(smoothing, grid_points,
MoreArgs = list(covid[, 1], grid_points,
bw = 3.5 / t_len))
smoothed_2  <- mapply(smoothing, grid_points,
MoreArgs = list(covid[, 2], grid_points,
bw = 3.5 / t_len))
plot(smoothed_1, ylim=c(min(covid[, 1], covid[, 2]),
max(covid[, 1], covid[, 2])),
type="l", col="blue", ylab="", xlab = "", mgp=c(1,0.5,0))
title(main = "(b) smoothed curves from (a)", font.main = 1,
line = 0.5)
lines(smoothed_2, col="red")
# Chunk 31
l <- 1 #First comparison in ijset
gset       <- results$gset_with_values[[l]]
reject     <- subset(gset, test == TRUE, select = c(u, h))
reject_set <- data.frame('startpoint' = (reject$u - reject$h) *
t_len,
'endpoint' = (reject$u + reject$h) *
t_len, 'values' = 0)
reject_set$values <- (1:nrow(reject_set)) / nrow(reject_set)
reject_min        <- compute_minimal_intervals(reject_set)
plot(NA, xlim=c(0, t_len),  ylim = c(0, 1 + 1 / nrow(reject_set)),
xlab="", mgp=c(2, 0.5, 0), yaxt = "n", ylab = "")
title(main = "(c) minimal intervals produced by our test",
font.main = 1, line = 0.5)
title(xlab = "days since the hundredth case", line = 1.7,
cex.lab = 0.9)
segments(reject_min$startpoint, reject_min$values,
reject_min$endpoint, reject_min$values, lwd = 2)
segments(reject_set$startpoint, reject_set$values,
reject_set$endpoint, reject_set$values,
col = "gray")
library(multiscale)
devtools::build_manual()
library(multiscale)
roxygen2::roxygenize()
library(multiscale)
